{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import skimage.io as io\n",
    "import thinplate as tps\n",
    "import cv2\n",
    "import skimage\n",
    "import dlib\n",
    "from skimage.color import rgb2gray,rgb2lab\n",
    "from scipy.sparse import spdiags\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TPS:       \n",
    "    @staticmethod\n",
    "    def fit(c, lambd=0., reduced=False):        \n",
    "        n = c.shape[0]\n",
    "\n",
    "        U = TPS.u(TPS.d(c, c))\n",
    "        K = U + np.eye(n, dtype=np.float32)*lambd\n",
    "\n",
    "        P = np.ones((n, 3), dtype=np.float32)\n",
    "        P[:, 1:] = c[:, :2]\n",
    "\n",
    "        v = np.zeros(n+3, dtype=np.float32)\n",
    "        v[:n] = c[:, -1]\n",
    "\n",
    "        A = np.zeros((n+3, n+3), dtype=np.float32)\n",
    "        A[:n, :n] = K\n",
    "        A[:n, -3:] = P\n",
    "        A[-3:, :n] = P.T\n",
    "\n",
    "        theta = np.linalg.solve(A, v) # p has structure w,a\n",
    "        return theta[1:] if reduced else theta\n",
    "        \n",
    "    @staticmethod\n",
    "    def d(a, b):\n",
    "        return np.sqrt(np.square(a[:, None, :2] - b[None, :, :2]).sum(-1))\n",
    "\n",
    "    @staticmethod\n",
    "    def u(r):\n",
    "        return r**2 * np.log(r + 1e-6)\n",
    "\n",
    "    @staticmethod\n",
    "    def z(x, c, theta):\n",
    "        x = np.atleast_2d(x)\n",
    "        U = TPS.u(TPS.d(x, c))\n",
    "        w, a = theta[:-3], theta[-3:]\n",
    "        reduced = theta.shape[0] == c.shape[0] + 2\n",
    "        if reduced:\n",
    "            w = np.concatenate((-np.sum(w, keepdims=True), w))\n",
    "        b = np.dot(U, w)\n",
    "        return a[0] + a[1]*x[:, 0] + a[2]*x[:, 1] + b\n",
    "\n",
    "def uniform_grid(shape):\n",
    "    '''Uniform grid coordinates.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    shape : tuple\n",
    "        HxW defining the number of height and width dimension of the grid\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    points: HxWx2 tensor\n",
    "        Grid coordinates over [0,1] normalized image range.\n",
    "    '''\n",
    "\n",
    "    H,W = shape[:2]    \n",
    "    c = np.empty((H, W, 2))\n",
    "    c[..., 0] = np.linspace(0, 1, W, dtype=np.float32)\n",
    "    c[..., 1] = np.expand_dims(np.linspace(0, 1, H, dtype=np.float32), -1)\n",
    "\n",
    "    return c\n",
    "    \n",
    "def tps_theta_from_points(c_src, c_dst, reduced=False):\n",
    "    delta = c_src - c_dst\n",
    "    \n",
    "    cx = np.column_stack((c_dst, delta[:, 0]))\n",
    "    cy = np.column_stack((c_dst, delta[:, 1]))\n",
    "        \n",
    "    theta_dx = TPS.fit(cx, reduced=reduced)\n",
    "    theta_dy = TPS.fit(cy, reduced=reduced)\n",
    "\n",
    "    return np.stack((theta_dx, theta_dy), -1)\n",
    "\n",
    "\n",
    "def tps_grid(theta, c_dst, dshape):    \n",
    "    ugrid = uniform_grid(dshape)\n",
    "\n",
    "    reduced = c_dst.shape[0] + 2 == theta.shape[0]\n",
    "\n",
    "    dx = TPS.z(ugrid.reshape((-1, 2)), c_dst, theta[:, 0]).reshape(dshape[:2])\n",
    "    dy = TPS.z(ugrid.reshape((-1, 2)), c_dst, theta[:, 1]).reshape(dshape[:2])\n",
    "    dgrid = np.stack((dx, dy), -1)\n",
    "\n",
    "    grid = dgrid + ugrid\n",
    "    \n",
    "    return grid # H'xW'x2 grid[i,j] in range [0..1]\n",
    "\n",
    "def tps_grid_to_remap(grid, sshape):\n",
    "    '''Convert a dense grid to OpenCV's remap compatible maps.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    grid : HxWx2 array\n",
    "        Normalized flow field coordinates as computed by compute_densegrid.\n",
    "    sshape : tuple\n",
    "        Height and width of source image in pixels.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mapx : HxW array\n",
    "    mapy : HxW array\n",
    "    '''\n",
    "\n",
    "    mx = (grid[:, :, 0] * sshape[1]).astype(np.float32)\n",
    "    my = (grid[:, :, 1] * sshape[0]).astype(np.float32)\n",
    "\n",
    "    return mx, my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image_cv(img, c_src, c_dst, dshape=None):\n",
    "    dshape = dshape or img.shape\n",
    "    theta = tps_theta_from_points(c_src, c_dst, reduced=True)\n",
    "    grid = tps_grid(theta, c_dst, dshape)\n",
    "    mapx, mapy = tps_grid_to_remap(grid, img.shape)\n",
    "    return cv2.remap(img, mapx, mapy, cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(image):\n",
    "    img = np.copy(image)\n",
    "    # set up the 68 point facial landmark detector\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    # bring in the input image\n",
    "    # img = cv2.imread('maxresdefault.jpg', 1)\n",
    "    \n",
    "    # convert to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the image\n",
    "    faces_in_image = detector(img_gray, 0)\n",
    "    # loop through each face in image\n",
    "    for face in faces_in_image:\n",
    "\n",
    "        # assign the facial landmarks\n",
    "        landmarksref = predictor(img_gray, face)\n",
    "\n",
    "        # unpack the 68 landmark coordinates from the dlib object into a list \n",
    "        landmarks_listref = []\n",
    "        v=[\n",
    "            [0,0],[1,0],[1,1],[0,1]\n",
    "        ]\n",
    "        for i in range(0, landmarksref.num_parts):\n",
    "            landmarks_listref.append((landmarksref.part(i).x, landmarksref.part(i).y))\n",
    "            v.append([(landmarksref.part(i).x)/img.shape[0], (landmarksref.part(i).y)/img.shape[1]])\n",
    "\n",
    "        # for each landmark, plot and write number\n",
    "        for landmark_numref, xy in enumerate(landmarks_listref, start = 1):\n",
    "            cv2.circle(img, (xy[0], xy[1]), 12, (168, 0, 20), -1)\n",
    "            cv2.putText(img, str(landmark_numref),(xy[0]-7,xy[1]+5), cv2.FONT_HERSHEY_SIMPLEX, 0.4,(255,255,255), 1)\n",
    "            \n",
    "    return landmarks_listref, v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(img_original):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    img = np.copy(img_original)\n",
    "    rect = detector(img)[0]\n",
    "    sp = predictor(img, rect)\n",
    "    landmarks = np.array([[p.x, p.y] for p in sp.parts()])\n",
    "\n",
    "    left_eye = landmarks[[*range(38,35,-1), *range(41,38,-1)]]\n",
    "    right_eye = landmarks[[*range(44,41,-1), *range(47,44,-1)]]\n",
    "    libs = landmarks[[*range(54,47,-1), *range(60,54,-1)]]\n",
    "    outline = landmarks[[*range(17), *range(26,16,-1)]]\n",
    "\n",
    "#     print(landmarks,outline)\n",
    "    \n",
    "    Y, X = skimage.draw.polygon(outline[:,1], outline[:,0])\n",
    "    # they are colored\n",
    "    Ylibs, Xlibs = skimage.draw.polygon(libs[:,1], libs[:,0])\n",
    "    Yle, Xle = skimage.draw.polygon(left_eye[:,1], left_eye[:,0])\n",
    "    Yre, Xre = skimage.draw.polygon(right_eye[:,1], right_eye[:,0])\n",
    "\n",
    "    cropped_img = np.zeros(img.shape, dtype=np.uint8)\n",
    "    # for libs and eyes\n",
    "    cropped_img_libs = np.zeros(img.shape, dtype=np.uint8)\n",
    "    cropped_img_leye = np.zeros(img.shape, dtype=np.uint8)\n",
    "    cropped_img_reye = np.zeros(img.shape, dtype=np.uint8)\n",
    "    # the line below means that we copy the shape(face) for the region of X and Y, to the black image(cropped_img)\n",
    "#     cropped_img[Y, X] = img[Y, X]\n",
    "    img[Ylibs, Xlibs] = cropped_img_libs[Ylibs, Xlibs]\n",
    "    img[Yle, Xle] = cropped_img_leye[Yle, Xle]\n",
    "    img[Yre, Xre] = cropped_img_reye[Yre, Xre]\n",
    "    cropped_img[Y, X] = img[Y, X]\n",
    "    img = img_original-cropped_img\n",
    "    return cropped_img,img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_libs(img_original):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    img = np.copy(img_original)\n",
    "    rect = detector(img)[0]\n",
    "    sp = predictor(img, rect)\n",
    "    landmarks = np.array([[p.x, p.y] for p in sp.parts()])\n",
    "\n",
    "    libs = landmarks[[*range(54,47,-1), *range(60,54,-1)]]\n",
    "\n",
    "    Ylibs, Xlibs = skimage.draw.polygon(libs[:,1], libs[:,0])\n",
    "\n",
    "    cropped_img_libs = np.zeros(img.shape, dtype=np.uint8)\n",
    "    # the line below means that we copy the shape(face) for the region of X and Y, to the black image(cropped_img)\n",
    "    \n",
    "    cropped_img_libs[Ylibs, Xlibs] = img[Ylibs, Xlibs]\n",
    "    \n",
    "    return cropped_img_libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wlsfilter_layer(image_orig, beta=0.2 ,lambda_=0.2):\n",
    "\n",
    "    image = image_orig.astype(np.float)/255.0\n",
    "    image1 = image.flatten(1)\n",
    "    s = image.shape\n",
    "    k = s[0]*s[1]\n",
    "\n",
    "    dy = np.diff(image, 1, 0)\n",
    "    dx = np.diff(image, 1, 1)\n",
    "    \n",
    "    dy = -beta*lambda_ / ((np.absolute(dy) ** 1.2 + 0.0001))\n",
    "    dx = -beta*lambda_ / ((np.absolute(dx) ** 1.2 + 0.0001))\n",
    "\n",
    "\n",
    "    dy = np.vstack((dy, np.zeros(s[1], )))\n",
    "    dx = np.hstack((dx, np.zeros(s[0], )[:, np.newaxis]))\n",
    "\n",
    "    dy = dy.flatten(1)\n",
    "    dx = dx.flatten(1)\n",
    "    \n",
    "    d = 1 - (dx + np.roll(dx, s[0]) + dy + np.roll(dy, 1))\n",
    "\n",
    "    a = spdiags(np.vstack((dx, dy)), [-s[0], -1], k, k)\n",
    "    a = a + a.T + spdiags(d, 0, k, k)\n",
    "\n",
    "    temp = spsolve(a, image1).reshape(s[::-1])\n",
    "    \n",
    "    base = np.rollaxis(temp,1)\n",
    "    detail = image - base\n",
    "    return (base), (detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Non-string object detected for the array ordering. Please pass in 'C', 'F', 'A', or 'K' instead\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Non-string object detected for the array ordering. Please pass in 'C', 'F', 'A', or 'K' instead\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Non-string object detected for the array ordering. Please pass in 'C', 'F', 'A', or 'K' instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imgr = cv2.imread('examples/80811699_418066922406466_6994441794444328960_n1.jpg', 1)\n",
    "# imgt = cv2.imread('input/79436089_822552084866705_868234996165378048_n.jpg', 1)\n",
    "\n",
    "# reference(with makeup)\n",
    "imgr = cv2.imread('detectedref.jpg', 1)\n",
    "# target(without makeup)\n",
    "imgt = cv2.imread('input/image1.png', 1)\n",
    "\n",
    "dim = (600, 600)\n",
    "imgr = cv2.resize(imgr, dim)\n",
    "\n",
    "dim = (600, 600)\n",
    "imgt = cv2.resize(imgt, dim)\n",
    "\n",
    "landmarkref,vref = face_detection(imgr)\n",
    "landmarktar,vtar = face_detection(imgt)\n",
    "\n",
    "# show_images([imgr, imgt], ['reference', 'target'])\n",
    "\n",
    "v_example = np.array(vref)\n",
    "v_input = np.array(vtar)\n",
    "\n",
    "veoutline = v_example[[*range(17), *range(26,16,-1)]]\n",
    "vioutline = v_input[[*range(17), *range(26,16,-1)]]\n",
    "\n",
    "wapred_img = warp_image_cv(imgr, veoutline, vioutline)\n",
    "\n",
    "# show_images([wapred_img], ['warped'])\n",
    "\n",
    "croppedtar_face , back_ground = crop_face(imgt)\n",
    "croppedref_face , back_groundref = crop_face(wapred_img)\n",
    "\n",
    "# show_images([croppedtar_face, croppedref_face], ['cropped face target', 'cropped face refernece'])\n",
    "# show_images([back_ground, back_groundref], ['background target', 'background reference'])\n",
    "\n",
    "croppedtar_lips = crop_libs(imgt)\n",
    "croppedref_lips = crop_libs(wapred_img)\n",
    "\n",
    "# show_images([croppedtar_lips, croppedref_lips], ['cropped lips target', 'cropped lips refernece'])\n",
    "\n",
    "imager_face = cv2.cvtColor(croppedref_face, cv2.COLOR_BGR2LAB)\n",
    "imaget_face = cv2.cvtColor(croppedtar_face, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "cv2.imwrite('imager_face.jpg',imager_face)\n",
    "cv2.imwrite('imaget_face.jpg',imaget_face)\n",
    "\n",
    "imager_lip = cv2.cvtColor(croppedref_lips, cv2.COLOR_BGR2LAB)\n",
    "imaget_lip = cv2.cvtColor(croppedtar_lips, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "cv2.imwrite('imager_lip.jpg',imager_lip)\n",
    "cv2.imwrite('imaget_lip.jpg',imaget_lip)\n",
    "\n",
    "LS_tar,D_tar = wlsfilter_layer (imaget_face[:,:,0])\n",
    "LS_ref,D_ref = wlsfilter_layer (imager_face[:,:,0])\n",
    "\n",
    "LS_tar_lip,D_tar_lip = wlsfilter_layer (imaget_lip[:,:,0])\n",
    "LS_ref_lip,D_ref_lip = wlsfilter_layer (imager_lip[:,:,0])\n",
    "\n",
    "D_res = D_ref + 0.5*D_tar\n",
    "D_res_lip = D_ref_lip + 0.5*D_tar_lip\n",
    "\n",
    "Rc_A = 0.2*imaget_face[:,:,1] + 0.8*imager_face[:,:,1]\n",
    "Rc_B = 0.2*imaget_face[:,:,2] + 0.8*imager_face[:,:,2]\n",
    "\n",
    "LIP_A = 0.2*imaget_lip[:,:,1] + 0.8*imager_lip[:,:,1]\n",
    "LIP_B = 0.2*imaget_lip[:,:,1] + 0.8*imager_lip[:,:,1]\n",
    "\n",
    "\n",
    "Rsum = imaget_face.copy() \n",
    "Rsum1 = imaget_lip.copy()\n",
    "\n",
    "Rsum[:,:,0] = (LS_tar + D_res)*255.0\n",
    "Rsum[:,:,1] = Rc_A \n",
    "Rsum[:,:,2] = Rc_B \n",
    "\n",
    "Rsum1[:,:,0] = (D_res_lip + LS_tar_lip)*255.0\n",
    "Rsum1[:,:,1] = LIP_A\n",
    "Rsum1[:,:,2] = LIP_B\n",
    "\n",
    "R = cv2.cvtColor(Rsum, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "R1 = cv2.cvtColor(Rsum1, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "result = R + R1\n",
    "# show_images([R, R1, result], ['resulted face', 'resulted lips', 'result cropped face'])\n",
    "\n",
    "background = back_ground-croppedtar_lips\n",
    "\n",
    "cv2.imwrite('result.jpg',result)\n",
    "cv2.imwrite('background.jpg',background)\n",
    "\n",
    "My_img = result + background\n",
    "\n",
    "# show_images([My_img], ['result output'])\n",
    "\n",
    "cv2.imshow(\"outImg\", My_img)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite('outImg.jpg', My_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
